#!/usr/bin/env python3
"""
COMPREHENSIVE REPORT GENERATOR
Generates holistic, user-friendly reports after complete threat analysis cycle
Clears memory dumps to save space
"""

import sys
import json
import shutil
from pathlib import Path
from datetime import datetime
from colorama import init, Fore, Back, Style

init(autoreset=True)

daemon_root = Path(__file__).parent.parent
sys.path.insert(0, str(daemon_root))

# ============================================================================
# COMPREHENSIVE REPORT GENERATOR
# ============================================================================

class ComprehensiveReportGenerator:
    """Generates holistic reports and manages memory dump cleanup"""
    
    def __init__(self, daemon_root: Path = None):
        """Initialize report generator"""
        self.daemon_root = daemon_root or Path(__file__).parent.parent
        self.reports_dir = self.daemon_root / "Reports"
        # Memory dumps are stored at root level, not in Daemon folder
        self.memory_dumps_dir = Path("F:/MalwareAnalysis/MemoryDumps")
        self.quarantine_dir = self.daemon_root / "Quarantine"
        self.logs_dir = self.daemon_root / "Logs"
        
        # Create organized report subdirectories
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self.markdown_reports_dir = self.reports_dir / "MarkdownReports"
        self.json_reports_dir = self.reports_dir / "JSONReports"
        self.markdown_reports_dir.mkdir(parents=True, exist_ok=True)
        self.json_reports_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_comprehensive_report(self, cycle_data: dict) -> str:
        """Generate complete holistic report for the cycle"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.markdown_reports_dir / f"COMPREHENSIVE_REPORT_{timestamp}.md"
        
        report_content = self._build_report_content(cycle_data, timestamp)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return str(report_file)
    
    def _build_report_content(self, cycle_data: dict, timestamp: str) -> str:
        """Build comprehensive report content"""
        
        threat_info = cycle_data.get('threat_info', {})
        preanalyzer_results = cycle_data.get('preanalyzer_results', {})
        dump_info = cycle_data.get('dump_info', {})
        volatility_results = cycle_data.get('volatility_results', {})
        enhanced_analysis = cycle_data.get('enhanced_analysis', {})
        terminator_results = cycle_data.get('terminator_results', {})
        
        report = f"""# COMPREHENSIVE MALWARE ANALYSIS REPORT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Report ID: {timestamp}

---

## EXECUTIVE SUMMARY

### Threat Overview
- **Threat Name**: {threat_info.get('name', 'Unknown')}
- **Threat Type**: {threat_info.get('threat_type', 'Unknown')}
- **Threat Level**: {threat_info.get('threat_level', 'Unknown')}
- **Risk Score**: {threat_info.get('risk_score', 'N/A')}/100
- **Status**: ✅ DETECTED AND NEUTRALIZED

### Key Findings
- **Process ID**: {threat_info.get('pid', 'N/A')}
- **Process Name**: {threat_info.get('name', 'Unknown')}
- **File Path**: {threat_info.get('path', 'Unknown')}
- **Detection Time**: {threat_info.get('detection_time', 'N/A')}

---

## DETAILED ANALYSIS

### 1. PREANALYZER DETECTION

#### Detection Method
PreAnalyzer performed comprehensive 7-layer malware detection:

1. **Name-Based Detection**: Scanning for malware keywords
2. **Path-Based Detection**: Checking suspicious file locations
3. **Behavioral Detection**: Analyzing CPU, memory, network usage
4. **Command Line Analysis**: Detecting obfuscation and suspicious commands
5. **System Process Impersonation**: Identifying process spoofing
6. **Process Injection Detection**: Finding code injection attempts
7. **Network Behavior Analysis**: Detecting C2 communication

#### Detection Results
"""
        
        # Add PreAnalyzer indicators
        if preanalyzer_results.get('indicators'):
            report += "\n**Detected Indicators**:\n"
            for indicator in preanalyzer_results['indicators'][:10]:
                report += f"- {indicator}\n"
        
        report += f"""

#### Confidence Level
- **Detection Confidence**: {preanalyzer_results.get('confidence', 'N/A')}%
- **Multiple Layers Triggered**: {len(preanalyzer_results.get('indicators', []))} indicators detected

---

### 2. IMMEDIATE RESPONSE

#### Actions Taken
1. ✅ **Process Suspended**: Prevented further execution
2. ✅ **File Quarantined**: Isolated to safe location
3. ✅ **Process Terminated**: Removed from system memory
4. ✅ **Memory Dump Initiated**: Captured forensic evidence

#### Quarantine Details
- **Quarantine Location**: {cycle_data.get('quarantine_location', 'N/A')}
- **File Preserved**: Yes (for recovery if needed)
- **Timestamp**: {cycle_data.get('quarantine_time', 'N/A')}

---

### 3. MEMORY FORENSICS

#### Memory Dump Strategy
- **Strategy Used**: {dump_info.get('strategy', 'N/A')}
- **Dump Size**: {dump_info.get('size', 'N/A')}
- **Dump Duration**: {dump_info.get('duration', 'N/A')}
- **Dump File**: {dump_info.get('file_path', 'N/A')}

#### Volatility Analysis
- **Commands Executed**: {volatility_results.get('commands_executed', 0)}/44
- **Success Rate**: {volatility_results.get('success_rate', 'N/A')}%
- **IOCs Found**: {len(volatility_results.get('iocs', []))} indicators of compromise

#### Key Findings from Memory Analysis
"""
        
        if volatility_results.get('iocs'):
            report += "\n**Indicators of Compromise**:\n"
            for ioc in volatility_results['iocs'][:5]:
                report += f"- {ioc}\n"
        
        report += f"""

---

### 4. BEHAVIORAL ANALYSIS

#### Threat Chain (MITRE ATT&CK)
"""
        
        if enhanced_analysis.get('threat_chain'):
            for technique in enhanced_analysis['threat_chain'][:5]:
                report += f"- **{technique.get('technique', 'Unknown')}**: {technique.get('description', 'N/A')}\n"
        
        report += f"""

#### Persistence Mechanisms Detected
"""
        
        if enhanced_analysis.get('persistence_mechanisms'):
            for mechanism in enhanced_analysis['persistence_mechanisms']:
                report += f"- {mechanism}\n"
        else:
            report += "- None detected\n"
        
        report += f"""

#### Risk Assessment
- **Overall Threat Score**: {enhanced_analysis.get('threat_score', 'N/A')}/100
- **Severity Level**: {enhanced_analysis.get('severity', 'N/A')}
- **Confidence**: {enhanced_analysis.get('confidence', 'N/A')}%

---

### 5. INTELLIGENT THREAT TERMINATION

#### 10-Layer Detection Results
"""
        
        if terminator_results.get('layer_results'):
            for layer_name, threats in terminator_results['layer_results'].items():
                if threats:
                    report += f"\n**{layer_name}**: {len(threats)} threat(s) detected\n"
                    for threat in threats[:3]:
                        report += f"  - {threat.get('type', 'Unknown')} [{threat.get('severity', 'N/A')}]\n"
        
        report += f"""

#### Related Threats Discovered
- **Total Related Threats**: {len(terminator_results.get('related_threats', []))}
- **All Quarantined**: Yes

"""
        
        if terminator_results.get('related_threats'):
            report += "**Related Threats**:\n"
            for related in terminator_results['related_threats'][:5]:
                report += f"- {related.get('name', 'Unknown')} (Risk: {related.get('risk_score', 'N/A')}/100)\n"
        
        report += f"""

#### System Protection Verification
- ✅ System Files Protected: Yes
- ✅ Daemon Files Protected: Yes
- ✅ Whitelisted Processes Protected: Yes
- ✅ No Legitimate Files Harmed: Confirmed

---

## RECOMMENDATIONS

### Immediate Actions
1. Review quarantined files in: {self.quarantine_dir}
2. Monitor system for related threats
3. Update antivirus signatures
4. Check for lateral movement attempts

### Long-Term Actions
1. Implement network segmentation
2. Enable endpoint detection and response (EDR)
3. Conduct security awareness training
4. Review access controls and permissions
5. Implement application whitelisting

### System Hardening
1. Disable unnecessary services
2. Enable Windows Defender
3. Keep OS and software updated
4. Enable Windows Firewall
5. Implement Group Policy restrictions

---

## TECHNICAL DETAILS

### File Information
- **File Name**: {threat_info.get('name', 'Unknown')}
- **File Path**: {threat_info.get('path', 'Unknown')}
- **File Size**: {threat_info.get('file_size', 'N/A')} bytes
- **File Hash (SHA256)**: {threat_info.get('file_hash', 'N/A')}

### Process Information
- **Process ID**: {threat_info.get('pid', 'N/A')}
- **Parent Process**: {threat_info.get('parent_process', 'N/A')}
- **Command Line**: {threat_info.get('cmdline', 'N/A')}
- **User Account**: {threat_info.get('user', 'N/A')}

### Network Activity
"""
        
        if volatility_results.get('network_connections'):
            report += "\n**Suspicious Connections**:\n"
            for conn in volatility_results['network_connections'][:5]:
                report += f"- {conn}\n"
        else:
            report += "- None detected\n"
        
        report += f"""

---

## RECOVERY INFORMATION

### Quarantine Location
All quarantined files are stored in:
```
{self.quarantine_dir}
```

### Recovery Instructions
If you need to recover a file:
1. Navigate to the quarantine folder
2. Find the timestamped folder for your threat
3. Copy the file back to its original location
4. Verify the file is legitimate before restoring

### Important Notes
- ✅ Original files are preserved in quarantine
- ✅ All actions are logged for audit trail
- ✅ System integrity maintained
- ✅ No data loss occurred

---

## CYCLE STATISTICS

### Timeline
- **Detection Time**: {cycle_data.get('detection_time', 'N/A')}
- **Analysis Duration**: {cycle_data.get('analysis_duration', 'N/A')}
- **Total Cycle Time**: {cycle_data.get('total_time', 'N/A')}

### Resource Usage
- **Memory Dump Size**: {dump_info.get('size', 'N/A')}
- **Analysis Files Generated**: {cycle_data.get('files_generated', 'N/A')}
- **Disk Space Used**: {cycle_data.get('disk_space_used', 'N/A')}

### Threats Handled
- **Primary Threat**: 1 (quarantined)
- **Related Threats**: {len(terminator_results.get('related_threats', []))} (all quarantined)
- **Total Threats Neutralized**: {1 + len(terminator_results.get('related_threats', []))}

---

## CONCLUSION

### Status: ✅ THREAT SUCCESSFULLY NEUTRALIZED

The malware analysis cycle has been completed successfully:

1. ✅ Threat detected and identified
2. ✅ Process suspended and terminated
3. ✅ File quarantined safely
4. ✅ Memory forensics completed
5. ✅ Behavioral analysis performed
6. ✅ Related threats discovered and quarantined
7. ✅ System files protected
8. ✅ Comprehensive report generated

### System Status
- **Current Status**: ✅ SECURE
- **Threats Active**: 0
- **Quarantined Items**: {len(list(self.quarantine_dir.glob('quarantine_*')))}
- **System Integrity**: ✅ INTACT

### Next Steps
1. Review this report carefully
2. Implement recommended actions
3. Monitor system for suspicious activity
4. Keep security software updated
5. Contact IT security if needed

---

## APPENDIX

### Glossary
- **IOC**: Indicator of Compromise - Evidence of malware activity
- **MITRE ATT&CK**: Framework of adversary tactics and techniques
- **Volatility**: Memory forensics framework
- **Quarantine**: Safe isolation of malicious files
- **Risk Score**: Numerical assessment of threat severity (0-100)

### Contact Information
For security concerns or questions about this report:
- Security Team: [Contact Info]
- Incident Response: [Contact Info]
- System Administrator: [Contact Info]

---

**Report Generated by: Enhanced Malware Analysis Daemon**
**Report ID: {timestamp}**
**Classification: INTERNAL USE ONLY**
"""
        
        return report
    
    def generate_json_report(self, cycle_data: dict) -> str:
        """Generate machine-readable JSON report"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.json_reports_dir / f"REPORT_{timestamp}.json"
        
        json_data = {
            'timestamp': timestamp,
            'report_type': 'comprehensive_cycle_report',
            'threat_info': cycle_data.get('threat_info', {}),
            'preanalyzer_results': cycle_data.get('preanalyzer_results', {}),
            'dump_info': cycle_data.get('dump_info', {}),
            'volatility_results': cycle_data.get('volatility_results', {}),
            'enhanced_analysis': cycle_data.get('enhanced_analysis', {}),
            'terminator_results': cycle_data.get('terminator_results', {}),
            'status': 'completed',
            'threats_neutralized': 1 + len(cycle_data.get('terminator_results', {}).get('related_threats', []))
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2)
        
        return str(report_file)
    
    def complete_cycle_and_restart(self) -> bool:
        """
        Complete the current cycle and prepare for restart
        Returns True if ready to restart, False otherwise
        """
        
        print(f"\n{Fore.CYAN}{'='*80}")
        print(f"CYCLE COMPLETION AND RESTART PREPARATION")
        print(f"{'='*80}\n")
        
        try:
            # Cleanup memory dumps
            cleanup_stats = self.cleanup_memory_dumps(keep_latest=1)
            
            # Prepare for restart
            print(f"\n{Fore.YELLOW}Preparing for next cycle...")
            print(f"{Fore.GREEN}✓ Memory dumps cleaned")
            print(f"{Fore.GREEN}✓ Reports generated")
            print(f"{Fore.GREEN}✓ System ready for restart")
            
            print(f"\n{Fore.CYAN}{'='*80}")
            print(f"RESTARTING PREANALYZER MONITORING")
            print(f"{'='*80}\n")
            
            return True
            
        except Exception as e:
            print(f"{Fore.RED}Error during cycle completion: {e}")
            return False
    
    def cleanup_memory_dumps(self, keep_latest: int = 1) -> dict:
        """Clean up memory dumps to save space - searches all subdirectories"""
        
        print(f"\n{Fore.CYAN}{'='*80}")
        print(f"MEMORY DUMP CLEANUP")
        print(f"{'='*80}\n")
        
        cleanup_stats = {
            'dumps_deleted': 0,
            'space_freed': 0,
            'dumps_kept': 0,
            'errors': [],
            'directories_scanned': []
        }
        
        try:
            # Define all dump subdirectories
            dump_subdirs = [
                self.memory_dumps_dir / "FullSystemDumps",
                self.memory_dumps_dir / "TargetedDumps",
                self.memory_dumps_dir / "ProcessDumps",
                self.memory_dumps_dir / "MinimalDumps",
                self.memory_dumps_dir / "LiveResponse",
                self.memory_dumps_dir / "AnalysisResults"
            ]
            
            all_dump_files = []
            
            # Scan all subdirectories for dump files
            for subdir in dump_subdirs:
                if subdir.exists():
                    cleanup_stats['directories_scanned'].append(subdir.name)
                    print(f"Scanning: {subdir.name}/")
                    
                    # Find all dump files in this directory (recursively for nested dirs)
                    try:
                        for dump_file in sorted(
                            list(subdir.glob("*")) + list(subdir.glob("*/*")),
                            key=lambda p: p.stat().st_mtime,
                            reverse=True
                        ):
                            if dump_file.is_file() or dump_file.is_dir():
                                all_dump_files.append(dump_file)
                    except Exception as e:
                        print(f"Error scanning {subdir.name}: {e}")
            
            if not all_dump_files:
                print(f"{Fore.YELLOW}No memory dumps found to clean up")
                print(f"{Fore.YELLOW}Checked directories: {', '.join([str(d) for d in dump_subdirs])}")
                return cleanup_stats
            
            print(f"\nFound {len(all_dump_files)} memory dump file(s)")
            print(f"Keeping latest {keep_latest} dump(s)\n")
            
            # Keep latest dumps, delete older ones
            for i, dump_file in enumerate(all_dump_files):
                if i < keep_latest:
                    print(f"{Fore.GREEN}✓ KEEPING: {dump_file.parent.name}/{dump_file.name}")
                    cleanup_stats['dumps_kept'] += 1
                else:
                    try:
                        # Calculate size before deletion
                        if dump_file.is_file():
                            size = dump_file.stat().st_size
                        else:
                            size = sum(
                                f.stat().st_size 
                                for f in dump_file.rglob('*') 
                                if f.is_file()
                            )
                        
                        # Delete dump
                        if dump_file.is_file():
                            dump_file.unlink()
                        else:
                            shutil.rmtree(dump_file)
                        
                        cleanup_stats['dumps_deleted'] += 1
                        cleanup_stats['space_freed'] += size
                        
                        size_mb = size / (1024 * 1024)
                        print(f"{Fore.GREEN}✓ DELETED: {dump_file.parent.name}/{dump_file.name} ({size_mb:.1f}MB)")
                        
                    except Exception as e:
                        cleanup_stats['errors'].append(str(e))
                        print(f"{Fore.RED}✗ ERROR deleting {dump_file.name}: {e}")
            
            # Print summary
            print(f"\n{Fore.CYAN}Cleanup Summary:")
            print(f"  Directories Scanned: {', '.join(cleanup_stats['directories_scanned'])}")
            print(f"  Dumps Deleted: {cleanup_stats['dumps_deleted']}")
            print(f"  Dumps Kept: {cleanup_stats['dumps_kept']}")
            print(f"  Space Freed: {cleanup_stats['space_freed'] / (1024*1024):.1f}MB")
            
            if cleanup_stats['errors']:
                print(f"  Errors: {len(cleanup_stats['errors'])}")
            
        except Exception as e:
            print(f"{Fore.RED}Cleanup error: {e}")
            cleanup_stats['errors'].append(str(e))
        
        return cleanup_stats
    
    def generate_cycle_summary(self, cycle_data: dict) -> str:
        """Generate quick summary for console output"""
        
        threat_info = cycle_data.get('threat_info', {})
        terminator_results = cycle_data.get('terminator_results', {})
        
        summary = f"""
{Fore.CYAN}{'='*80}
CYCLE COMPLETION SUMMARY
{'='*80}{Style.RESET_ALL}

{Fore.GREEN}✓ THREAT NEUTRALIZED{Style.RESET_ALL}
  Threat: {threat_info.get('name', 'Unknown')}
  Type: {threat_info.get('threat_type', 'Unknown')}
  Level: {threat_info.get('threat_level', 'Unknown')}
  Risk Score: {threat_info.get('risk_score', 'N/A')}/100

{Fore.GREEN}✓ ACTIONS COMPLETED{Style.RESET_ALL}
  1. Process suspended and terminated
  2. File quarantined safely
  3. Memory forensics completed
  4. Behavioral analysis performed
  5. Related threats discovered: {len(terminator_results.get('related_threats', []))}
  6. All threats quarantined
  7. System files protected
  8. Reports generated

{Fore.GREEN}✓ SYSTEM STATUS{Style.RESET_ALL}
  Current Status: SECURE
  Threats Active: 0
  Quarantined Items: {len(list(self.quarantine_dir.glob('quarantine_*')))}
  System Integrity: INTACT

{Fore.GREEN}✓ REPORTS GENERATED{Style.RESET_ALL}
  Markdown Report: Reports/COMPREHENSIVE_REPORT_*.md
  JSON Report: Reports/REPORT_*.json
  
{Fore.YELLOW}Next Steps:{Style.RESET_ALL}
  1. Review the comprehensive report
  2. Implement recommended actions
  3. Monitor system for suspicious activity
  4. Keep security software updated

{Fore.CYAN}{'='*80}{Style.RESET_ALL}
"""
        
        return summary


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Test report generator"""
    
    # Sample cycle data
    cycle_data = {
        'threat_info': {
            'name': 'ransomware_test.py',
            'threat_type': 'RANSOMWARE',
            'threat_level': 'CRITICAL',
            'risk_score': 85,
            'pid': 7400,
            'path': 'f:\\MalwareAnalysis\\ProcessManager\\ransomware_test.py',
            'detection_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        },
        'preanalyzer_results': {
            'indicators': [
                'Ransomware keyword: ransomware',
                'Ransomware keyword: ransomware_test',
                'Suspicious process behavior detected',
                'Network communication detected',
            ],
            'confidence': 95,
        },
        'dump_info': {
            'strategy': 'TARGETED_KERNEL',
            'size': '3.2GB',
            'duration': '5 minutes',
            'file_path': 'TargetedKernelDump_ransomware_test_20251119_000000.raw',
        },
        'volatility_results': {
            'commands_executed': 44,
            'success_rate': 100,
            'iocs': [
                'Injected code found',
                'Process injection detected',
                'Suspicious network connection',
            ],
            'network_connections': [
                '185.220.101.1:4444 (C2 Server)',
                '192.168.1.100:445 (SMB)',
            ],
        },
        'enhanced_analysis': {
            'threat_score': 85,
            'severity': 'CRITICAL',
            'confidence': 98,
            'threat_chain': [
                {'technique': 'Persistence', 'description': 'Scheduled task creation'},
                {'technique': 'Privilege Escalation', 'description': 'UAC bypass attempt'},
            ],
            'persistence_mechanisms': [
                'Scheduled Task: "Windows Update Service"',
                'Registry Entry: HKLM\\Run\\Malware',
            ],
        },
        'terminator_results': {
            'layer_results': {
                'File Signature Detection': [
                    {'type': 'SIGNATURE_RANSOMWARE', 'severity': 'HIGH'},
                ],
                'Network-Based Detection': [
                    {'type': 'C2_IP_PATTERN', 'severity': 'CRITICAL'},
                ],
            },
            'related_threats': [
                {'name': 'ransomware_v2.py', 'risk_score': 75},
                {'name': 'malware.exe', 'risk_score': 65},
            ],
        },
        'quarantine_location': 'f:\\MalwareAnalysis\\Daemon\\Quarantine\\quarantine_20251119_000000_ransomware_test\\',
        'quarantine_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'analysis_duration': '15 minutes',
        'total_time': '20 minutes',
        'files_generated': 47,
        'disk_space_used': '3.5GB',
    }
    
    # Generate reports
    generator = ComprehensiveReportGenerator()
    
    print(f"\n{Fore.CYAN}Generating comprehensive reports...")
    
    # Generate markdown report
    md_report = generator.generate_comprehensive_report(cycle_data)
    print(f"{Fore.GREEN}✓ Markdown report: {md_report}")
    
    # Generate JSON report
    json_report = generator.generate_json_report(cycle_data)
    print(f"{Fore.GREEN}✓ JSON report: {json_report}")
    
    # Print summary
    summary = generator.generate_cycle_summary(cycle_data)
    print(summary)
    
    # Cleanup memory dumps
    cleanup_stats = generator.cleanup_memory_dumps(keep_latest=1)
    
    print(f"\n{Fore.GREEN}Report generation complete!")


if __name__ == "__main__":
    main()
